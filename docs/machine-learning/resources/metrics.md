---
title: ML.NET 메트릭
description: ML.NET 모델의 성능을 평가하기 위해 사용한 메트릭 이해
ms.date: 12/17/2019
ms.openlocfilehash: 046e0a3feea2da702dfef5ca9ce4f498fce5fb26
ms.sourcegitcommit: 0802ac583585110022beb6af8ea0b39188b77c43
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/26/2020
ms.locfileid: "91804824"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="de77e-103">메트릭을 사용하여 ML.NET 모델 평가</span><span class="sxs-lookup"><span data-stu-id="de77e-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="de77e-104">ML.NET 모델을 평가하는 데 사용되는 메트릭을 파악합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="de77e-105">평가 메트릭은 모델에서 수행하는 기계 학습 작업의 유형에만 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="de77e-106">예를 들어 분류 작업의 경우 예측된 범주가 실제 범주와 일치하는 정도를 측정하여 모델을 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="de77e-107">클러스터링의 경우 평가는 클러스터된 항목을 서로 분리하는 방법 및 클러스터 간의 분리 정도를 기준으로 합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="de77e-108">이진 분류에 대한 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="de77e-109">metrics</span><span class="sxs-lookup"><span data-stu-id="de77e-109">Metrics</span></span>   |      <span data-ttu-id="de77e-110">설명</span><span class="sxs-lookup"><span data-stu-id="de77e-110">Description</span></span>      |  <span data-ttu-id="de77e-111">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="de77e-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="de77e-112">**정확도(Accuracy)**</span><span class="sxs-lookup"><span data-stu-id="de77e-112">**Accuracy**</span></span> |  <span data-ttu-id="de77e-113">[정확도](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)는 테스트 데이터 세트 사용 시 올바른 예측의 비율입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="de77e-114">총 입력 샘플 수 대비 올바른 예측 수의 비율입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="de77e-115">각 클래스에 유사한 수의 샘플이 속해 있는 경우에 제대로 작동합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="de77e-116">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="de77e-117">하지만 정확하게 1.00은 문제(일반적으로 레이블/대상 누출, 오버피팅 또는 학습 데이터 테스트)를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="de77e-118">테스트 데이터의 균형이 맞지 않은 경우(대부분 인스턴스가 클래스 중 하나에 속해 있는 경우) 데이터 세트가 작거나 점수가 0.00 또는 1.00에 근접하면 정확도는 실제로 분류자의 유효성을 포착하지 못하므로 추가 메트릭을 확인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn't really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="de77e-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="de77e-119">**AUC**</span></span> |    <span data-ttu-id="de77e-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) 또는 *곡선 아래의 영역* 은 진양성 비율과 가양성 비율을 스윕하여 생성된 곡선 아래의 영역을 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="de77e-121">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="de77e-122">모델이 허용되려면 그 값이 0.50보다 커야 합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="de77e-123">AUC가 0.50 이하인 모델은 유용하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="de77e-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="de77e-124">**AUCPR**</span></span> | <span data-ttu-id="de77e-125">aucPR 또는 *정밀도-리콜 곡선의 아래의 영역*: 클래스의 균형이 좋지 않을 때(상당히 기울어진 데이터 세트) 예측 성공에 대한 의미 있는 측정값입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-125">aucPR or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="de77e-126">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="de77e-127">1\.00에 가까운 고득점은 분류자가 정확한 결과(높은 정밀도)를 반환할 뿐만 아니라 대다수가 모두 긍정 결과(높은 재현율)를 반환하고 있음을 보여줍니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="de77e-128">**F1-점수(F1-score)**</span><span class="sxs-lookup"><span data-stu-id="de77e-128">**F1-score**</span></span> | <span data-ttu-id="de77e-129">*balanced F-score 또는 F-measure* 라고도 하는 [F1 점수](https://en.wikipedia.org/wiki/F1_score)는</span><span class="sxs-lookup"><span data-stu-id="de77e-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="de77e-130">정밀도와 재현율의 조화 평균입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="de77e-131">F1 점수는 정밀도(Precision)와 재현율(Recall) 간 균형을 찾으려고 할 때 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="de77e-132">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="de77e-133">F1 점수에서 가장 높은 값은 1.00이고 가장 낮은 점수는 0.00으로,</span><span class="sxs-lookup"><span data-stu-id="de77e-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="de77e-134">분류자의 정밀도를 알려줍니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="de77e-135">이진 분류 메트릭에 대한 자세한 내용은 다음 메트릭 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="de77e-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="de77e-136">정확도, 정밀도, 재현율 또는 F1?</span><span class="sxs-lookup"><span data-stu-id="de77e-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="de77e-137">이진 분류 메트릭 클래스</span><span class="sxs-lookup"><span data-stu-id="de77e-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="de77e-138">정밀도-재현율과 ROC 곡선 간의 관계</span><span class="sxs-lookup"><span data-stu-id="de77e-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="de77e-139">다중 클래스 분류에 대한 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="de77e-140">metrics</span><span class="sxs-lookup"><span data-stu-id="de77e-140">Metrics</span></span>   |      <span data-ttu-id="de77e-141">설명</span><span class="sxs-lookup"><span data-stu-id="de77e-141">Description</span></span>      |  <span data-ttu-id="de77e-142">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="de77e-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="de77e-143">**Micro-정확도**</span><span class="sxs-lookup"><span data-stu-id="de77e-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="de77e-144">[Micro 평균 정확도](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy)는 모든 클래스의 기여도를 집계하여 평균 메트릭을 컴퓨팅합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="de77e-145">정확하게 예측된 인스턴스의 일부분으로서,</span><span class="sxs-lookup"><span data-stu-id="de77e-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="de77e-146">Micro-평균은 클래스 멤버 자격을 고려하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="de77e-147">기본적으로, 모든 샘플-클래스 쌍은 정확도 메트릭에 동일기하게 기여합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="de77e-148">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="de77e-149">다중 클래스 분류 작업에서는 클래스 불균형이 있을 것으로 의심되는 경우(예:</span><span class="sxs-lookup"><span data-stu-id="de77e-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="de77e-150">다른 클래스의 예보다 한 클래스의 예가 훨씬 많을 수 있음) Macro-정확도보다 Micro-정확도가 더 낫습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="de77e-151">**Macro-정확도**</span><span class="sxs-lookup"><span data-stu-id="de77e-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="de77e-152">[Macro-평균 정확도](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy)는 클래스 수준에서는 평균 정확도입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="de77e-153">각 클래스에 대한 정확도가 계산되고 Macro-정확도는 이러한 정확도의 평균입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="de77e-154">기본적으로, 모든 클래스는 정확도 메트릭에 동일하게 기여합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="de77e-155">소수 클래스는 큰 클래스와 같은 가중치를 부여받습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="de77e-156">Macro-평균 메트릭은 데이터 세트에 포함된 클래스의 인스턴스 수가 얼마나 많던지 상관없이 각 클래스에 동일한 가중치를 부여합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="de77e-157">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="de77e-158">각 클래스에 대해 독립적으로 메트릭을 계산한 다음, 평균을 냅니다(따라서 모든 클래스를 동일하게 처리).</span><span class="sxs-lookup"><span data-stu-id="de77e-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="de77e-159">**로그 손실**</span><span class="sxs-lookup"><span data-stu-id="de77e-159">**Log-loss**</span></span>| <span data-ttu-id="de77e-160">로그 손실은 분류 모델의 성과를 측정합니다. 여기에서 예측 입력은 0.00과 1.00 사이의 확률 값입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-160">Logarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="de77e-161">로그 손실은 예측된 확률이 실제 레이블에서 나뉘면서 증가합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="de77e-162">**0.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="de77e-163">완벽한 모델은 로그 손실이 0.00이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="de77e-164">기계 학습 모델의 목표는 이 값을 최소화하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="de77e-165">**로그 손실 감소(Log-Loss Reduction)**</span><span class="sxs-lookup"><span data-stu-id="de77e-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="de77e-166">[로그 손실 감소](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction)는 임의 예측에 대한 분류자의 이점으로 해석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="de77e-167">**-inf ~1.00의 범위입니다. 여기서 1.00은 완벽한 예측이고 0.00은 평균 예측을 나타냅니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="de77e-168">예를 들어 값이 0.20이라면 “정확한 예측의 확률이 임의 추측보다 20% 나음”으로 해석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="de77e-169">Micro-정확도는 일반적으로 ML 예측의 비즈니스 요구 사항과 더 잘 맞습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="de77e-170">다중 클래스 분류 작업의 품질을 선택하기 위해 단일 메트릭을 선택하려는 경우 일반적으로 micro-정확도여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="de77e-171">예를 들어, 지원 티켓 분류 작업: (들어오는 티켓을 지원 팀에 매핑)</span><span class="sxs-lookup"><span data-stu-id="de77e-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="de77e-172">Micro-정확도 - 들어오는 티켓이 올바른 팀으로 분류되는 빈도</span><span class="sxs-lookup"><span data-stu-id="de77e-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="de77e-173">Macro-정확도 - 평균 팀의 경우 들어오는 티켓이 해당 팀에 정확한 빈도</span><span class="sxs-lookup"><span data-stu-id="de77e-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="de77e-174">Macro-정확도는 이 예에서 작은 팀에 가중치를 초과 부과합니다. 여기서 작은 팀은 매년 10개의 티켓을 받고, 큰 팀은 매년 1만 개의 티켓을 받습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="de77e-175">이 경우에 Micro-정확도는 “내 티켓 라우팅 프로세스를 자동화하여 회사가 절감할 수 있는 시간/비용 정도”라는 비즈니스 요구 사항과 상관 관계가 더 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="de77e-176">다중 클래스 분류 메트릭에 대한 더 자세한 내용은 다음 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="de77e-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="de77e-177">정밀도, 재현율 및 F 점수의 Micro-및 Macro-평균</span><span class="sxs-lookup"><span data-stu-id="de77e-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="de77e-178">불균형 데이터 세트를 사용한 다중 클래스 분류</span><span class="sxs-lookup"><span data-stu-id="de77e-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="de77e-179">회귀용 평가 메트릭 및 권장 사항</span><span class="sxs-lookup"><span data-stu-id="de77e-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="de77e-180">회귀 및 권장 사항 작업 모두 숫자를 예측합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="de77e-181">회귀의 경우 숫자는 입력 속성의 영향을 받는 모든 출력 속성이 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="de77e-182">권장 사항은 일반적으로 등급 값(예: 1에서 5 사이) 또는 예/아니요 권장 사항(각각 1과 0으로 표시됨)입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="de77e-183">메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-183">Metric</span></span>   |      <span data-ttu-id="de77e-184">설명</span><span class="sxs-lookup"><span data-stu-id="de77e-184">Description</span></span>      |  <span data-ttu-id="de77e-185">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="de77e-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="de77e-186">**R-제곱(R-Squared)**</span><span class="sxs-lookup"><span data-stu-id="de77e-186">**R-Squared**</span></span> |  <span data-ttu-id="de77e-187">[R-제곱(R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) 또는 *결정 계수* 는 -inf와 1.00 사이의 값으로 모델의 예측력을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="de77e-188">1.00은 완벽한 적합도를 의미하며, 적합도는 임의적으로 나쁠 수 있으므로 점수는 음수가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="de77e-189">점수 0.00은 모델이 레이블의 예상 값을 추측하고 있음을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="de77e-190">R2는 실제 테스트 데이터 값이 예측 값에 근접한 정도를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="de77e-191">**1.00에 가까울 수록 품질이 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="de77e-192">단, 낮은 R-제곱 값(예: 0.50)이 사용자의 시나리오에 완전히 정상이거나 충분히 좋을 수 있으며 높은 R-제곱 값이 항상 좋고 의심스러운 것이 아닌 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="de77e-193">**절대-손실(Absolute-loss)**</span><span class="sxs-lookup"><span data-stu-id="de77e-193">**Absolute-loss**</span></span> |  <span data-ttu-id="de77e-194">[절대 손실](https://en.wikipedia.org/wiki/Mean_absolute_error) 또는 *평균 절대 오차(MAE)* 는 예측이 실제 결과에 근접한 정도를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="de77e-195">모든 모델 오차의 평균이며, 여기서 모델 오차는 예측된 레이블 값과 올바른 레이블 값 사이의 절대 거리입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="de77e-196">이 예측 오차는 테스트 데이터 세트의 각 레코드에 대해 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="de77e-197">마지막으로, 평균 값은 모든 기록된 절대 오차에 대해 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="de77e-198">**0.00에 가까울 수록 품질이 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="de77e-199">절대 평균 오차는 측정 중인 데이터와 동일한 척도를 사용합니다(특정 범위로 정규화되지 않음).</span><span class="sxs-lookup"><span data-stu-id="de77e-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="de77e-200">절대-손실, 제곱근-손실 및 RMS 손실은 레이블 값 분산이 유사한 데이터 세트 또는 동일한 데이터 세트의 모델 간에 비교하기 위해서만 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="de77e-201">**제곱-손실(Squared-loss)**</span><span class="sxs-lookup"><span data-stu-id="de77e-201">**Squared-loss**</span></span> |  <span data-ttu-id="de77e-202">*평균 제곱 편차(MSD)* 라고도 하는 [제곱-손실](https://en.wikipedia.org/wiki/Mean_squared_error) 또는 *평균 제곱 오차(MSE)* 는 점에서 회귀선까지의 거리(오류 E)로 이동하고 이를 제곱하는 방식으로 테스트 데이터 값 집합에 대한 회귀선 근접 정도를 알려줍니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="de77e-203">제곱은 큰 차이에 더 많은 가중치를 부여합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="de77e-204">항상 음수가 아니며 **값이 0.00에 가까울 수록 더 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="de77e-205">데이터에 따라 평균 제곱근 오차의 아주 작은 값을 가져오는 것이 불가능할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="de77e-206">**RMS-손실(RMS-loss)**</span><span class="sxs-lookup"><span data-stu-id="de77e-206">**RMS-loss**</span></span> |  <span data-ttu-id="de77e-207">[RMS-손실](https://en.wikipedia.org/wiki/Root-mean-square_deviation) 또는 *평균 제곱 오차(Root Mean Square Error, RMSE)* (또는 *평균 제곱 편차(Root Mean Square Deviation, RMSD*))는 모델에서 예측한 값과 모델링하려는 환경에서 관찰된 값 사이의 차이를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="de77e-208">RMS-손실은 제곱 손실의 제곱근이며 큰 차이에 더 많은 가중치를 부여함으로써 절대-손실과 유사하게, 레이블과 단위가 동일합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="de77e-209">평균 제곱 오차는 실험적 결과를 검증하기 위해 일반적으로 기후학, 예측 및 회귀 분석에 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="de77e-210">항상 음수가 아니며 **값이 0.00에 가까울 수록 더 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="de77e-211">RMSD는 척도 종속적이므로, 데이터 세트 간이 아니라 특정 데이터 세트에 대해 다양한 모델의 예측 오차를 비교하기 위한 정확도 측도입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="de77e-212">회귀 메트릭에 대한 자세한 내용은 다음 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="de77e-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="de77e-213">회귀 분석: R-제곱을 해석하고 적합성(Goodness-of-Fit)을 평가하려면 어떻게 하나요?</span><span class="sxs-lookup"><span data-stu-id="de77e-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="de77e-214">회귀 분석에서 R-제곱을 해석하는 방법</span><span class="sxs-lookup"><span data-stu-id="de77e-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="de77e-215">R-제곱 정의</span><span class="sxs-lookup"><span data-stu-id="de77e-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="de77e-216">평균 제곱 오차 정의</span><span class="sxs-lookup"><span data-stu-id="de77e-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="de77e-217">평균 제곱 오차 및 평균 제곱근 오차의 정의</span><span class="sxs-lookup"><span data-stu-id="de77e-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="de77e-218">클러스터링에 대한 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="de77e-219">메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-219">Metric</span></span>   |      <span data-ttu-id="de77e-220">설명</span><span class="sxs-lookup"><span data-stu-id="de77e-220">Description</span></span>      |  <span data-ttu-id="de77e-221">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="de77e-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="de77e-222">**평균 거리**</span><span class="sxs-lookup"><span data-stu-id="de77e-222">**Average Distance**</span></span>|<span data-ttu-id="de77e-223">데이터 포인트와 할당된 클러스터의 중심 간 거리의 평균입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="de77e-224">평균 거리는 클러스터 중심에 대한 데이터 포인트 유사성을 측정한 것입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="de77e-225">클러스터의 '밀집' 정도에 대한 측정값입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="de77e-226">값이 **0** 에 가까울수록 바람직합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-226">Values closer to **0** are better.</span></span> <span data-ttu-id="de77e-227">평균 거리가 0에 가까울수록 데이터가 더 클러스터됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="de77e-228">그러나 클러스터 수가 증가하는 경우에는 이 메트릭이 줄어들고 극단적인 경우(각 고유 데이터 포인트가 자체 클러스터임)에는 0이 되기도 합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="de77e-229">**Davies Bouldin 인덱스**</span><span class="sxs-lookup"><span data-stu-id="de77e-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="de77e-230">클러스터 내 거리에서 클러스터 간 거리의 평균 비율입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="de77e-231">클러스터가 밀집되어 있고 잘 나누어진 경우 이 값은 낮습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="de77e-232">값이 **0** 에 가까울수록 바람직합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-232">Values closer to **0** are better.</span></span> <span data-ttu-id="de77e-233">잘 나누어져 있고 적게 분산된 클러스터는 더 나은 점수로 이어집니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="de77e-234">**정규화된 상호 정보**</span><span class="sxs-lookup"><span data-stu-id="de77e-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="de77e-235">클러스터링 모델을 학습하는 데 사용된 학습 데이터가 정확한 레이블(감독된 클러스터링)과 함께 제공될 때 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="de77e-236">정규화된 상호 정보 메트릭은 유사한 데이터 포인트가 동일한 클러스터에 할당되고 다른 데이터 포인트가 다른 클러스터에 할당되는지 여부를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="de77e-237">정규화된 상호 정보는 0에서 1 사이의 값입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="de77e-238">값이 **1** 에 가까울수록 바람직합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="de77e-239">순위 지정에 대한 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="de77e-240">메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-240">Metric</span></span>   |      <span data-ttu-id="de77e-241">설명</span><span class="sxs-lookup"><span data-stu-id="de77e-241">Description</span></span>      |  <span data-ttu-id="de77e-242">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="de77e-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="de77e-243">**Discounted Cumulative Gain**</span><span class="sxs-lookup"><span data-stu-id="de77e-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="de77e-244">DCG(Discounted Cumulative Gain)는 순위 지정의 척도입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="de77e-245">이는 두 가지 가정에서 파생됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-245">It is derived from two assumptions.</span></span> <span data-ttu-id="de77e-246">첫 번째는 다음과 같습니다. 순위 지정 순서가 높을수록 관련성이 높은 항목이 더 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="de77e-247">두 번째는 다음과 같습니다. 유용성은 관련성을 추적합니다. 즉 관련성이 높을수록 항목이 더 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="de77e-248">DCG는 순위 지정 순서의 특정 위치에 대해 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="de77e-249">관련성 등급을 순위 지정 인덱스의 로그로 나눈 값을 관심 위치까지 합산합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="de77e-250">$\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ 공식을 사용하여 계산됩니다. 관련성 등급은 순위 지정 학습 알고리즘에 정확한 레이블로 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="de77e-251">순위 지정 테이블의 각 위치에 대해 하나의 DCG 값이 제공되므로 이름이 Discounted Cumulative **Gain** 입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="de77e-252">**값이 높을수록 좋음**</span><span class="sxs-lookup"><span data-stu-id="de77e-252">**Higher values are better**</span></span>|
|<span data-ttu-id="de77e-253">**Normalized Discounted Cumulative Gain**</span><span class="sxs-lookup"><span data-stu-id="de77e-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="de77e-254">DCG를 정규화하면 다른 길이의 순위 목록에 대해 메트릭을 비교할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="de77e-255">**1에 가까운 값이 더 좋음**</span><span class="sxs-lookup"><span data-stu-id="de77e-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="de77e-256">변칙 검색에 대한 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="de77e-257">메트릭</span><span class="sxs-lookup"><span data-stu-id="de77e-257">Metric</span></span>   |      <span data-ttu-id="de77e-258">설명</span><span class="sxs-lookup"><span data-stu-id="de77e-258">Description</span></span>      |  <span data-ttu-id="de77e-259">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="de77e-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="de77e-260">**ROC 곡선 아래의 영역**</span><span class="sxs-lookup"><span data-stu-id="de77e-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="de77e-261">ROC 곡선 아래의 영역은 모델이 비정상 데이터와 일반적인 데이터 포인트를 얼마나 잘 분리하는지 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="de77e-262">**1에 가까운 값이 더 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="de77e-263">값이 0.5보다 커야만 모델이 효과가 있음을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="de77e-264">0\.5 이하의 값은 입력을 비정상 및 일반 범주에 임의로 할당하는 것보다 모델이 좋지 않다는 의미입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="de77e-265">**가양성 수의 검색 비율**</span><span class="sxs-lookup"><span data-stu-id="de77e-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="de77e-266">가양성 수의 검색 비율은 각각의 가양성으로 인덱싱되는 테스트 집합에서 비정상의 총 수에 대해 올바르게 식별된 비정상 수의 비율입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="de77e-267">즉, 각 가양성 항목에 대해 가양성 수의 검색 비율 값이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="de77e-268">**1에 가까운 값이 더 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="de77e-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="de77e-269">가양성이 없으면 이 값은 1입니다.</span><span class="sxs-lookup"><span data-stu-id="de77e-269">If there are no false positives, then this value is 1</span></span>|
